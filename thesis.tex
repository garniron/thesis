\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{caption}
\captionsetup{font=footnotesize}
\usepackage{amsmath}
%\usepackage{algorithm}
\usepackage{listings}
%\usepackage{standalone}
%\usepackage{algpseudocode}
\usepackage[linesnumbered,lined,boxed,commentsnumbered]{algorithm2e}
\SetKw{KwBy}{by} 
\newcommand\mycommfont[1]{\footnotesize\ttfamily{#1}}
\SetCommentSty{mycommfont}
\usepackage{verbatim}
\usepackage{tabularx}
%\usepackage{program}
%\input{externaldoc}
%\input{verticalblock}
%\algrenewcommand\algorithmicindent{1.0em}
\usepackage{minitoc}
\usepackage{float}
\usepackage{hyperref}
\usepackage{physics}
\usepackage{color}
\usepackage{subfiles}
\usepackage{pdfpages}
\usepackage{centernot}
\usepackage[ED=SDM-PMat, Ets=UT3]{tlsflyleaf}

\hypersetup{
 colorlinks=true,
 linkcolor=blue,
 filecolor=blue,
 urlcolor=blue,
 citecolor=blue
}
\usepackage{mathpazo,libertine}



\input{macros}



%%%%%
% À mettre dans le préambule (avant \begin{document})
%%%%%
%% Titre, auteur, date, laboratoire, cotutelle
%\title{Development and parallel implementation of Selected Configuration Interaction methods}
\title{Développement et implémentation parallèle de méthodes d'interaction de configurations sélectionnées}
\author{Yann GARNIRON}
\defencedate{15/11/2018}
\lab{Laboratoire de Chimie et Physique Quantiques (UMR 5626)}
%\cotutelle{Institut de cotutelle}

%% Directeur(s) de thèse
\nboss{1}                                    % Nombre de directeur(s) de thèse
\makesomeone{boss}{1}{Anthony SCEMAMA}{Ingénieur de Recherche}{Directeur} % Sera affiché en premier
%% Referee
\nreferee{2}
\makesomeone{referee}{1}{Philippe CARBONNIERE}{Professeur d'Université}{Rapporteur}
\makesomeone{referee}{2}{Jean-Philip PIQUEMAL}{Professeur d'Université}{Rapporteur}
%% Jury
\njudge{2}
\makesomeone{judge}{1}{Nathalie GUIHERY}{Professeure d'Université}{Président du Jury}
\makesomeone{judge}{2}{Nicolas RENON}{Ingénieur de Recherche}{Examinateur}
%\makesomeone{judge}{3}{Troisième MEMBRE}{Chargé de Recherche}{}


\usepackage[square,sort,comma,numbers]{natbib}
\usepackage{graphicx}


\lstset{% setup listings
        language=Fortran,% set programming language
        basicstyle=\ttfamily\footnotesize,% basic font style
%       keywordstyle=\bfseries,% keyword style
%        commentstyle=\ttfamily\itshape,% comment style
%       numbers=left,% display line numbers on the left side
%       numberstyle=\scriptsize,% use small line numbers
%       numbersep=10pt,% space between line numbers and code
        tabsize=2,% sizes of tabs
        showstringspaces=false,% do not replace spaces in strings by a certain character
        captionpos=b,% positioning of the caption below
        breaklines=true,% automatic line breaking
        escapeinside={(*}{*)},% escaping to LaTeX
        extendedchars=false,% prohibit extended chars (chars of codes 128--255)
        otherkeywords={assert,
            POPCNT, ISHFT, IBCLR, IOR, IEOR, TRAILZ, IAND, NOT, BTEST}
}



\begin{document}

\dominitoc

%\makeflyleaf
\includepdf{couverture_these}
\newpage

\chapter*{Acknowledgments - PROBLEMS}



%Alors?? Tu n'ecris pas ta these ???


ref au iterative CI voir si c'est la bonne (Nakatsuji ajouté mais pas cité)

citation "Sutter\_2005" dans l'intro ne passe pas...


\newpage

\tableofcontents
\newpage

\section*{Notations}

\begin{itemize}

\item [$\Norb$] Number of molecular orbitals

\item [$\Nst$] Number of considered eigenstates

\item [$\Ndet$] Number of determinants in the internal space

\item [$\Ngen$] Number of generator determinants 

\item [$\Nsel$] Number of selector determinants

\item [$\Nelec$] Number of electrons

\item [$\Nalpha$] Number of $\alpha$-spin electrons

\item [$\Nbeta$] Number of $\beta$-spin electrons

\item [$\Nint$] : Number of 64-bit integers required to store $\Norb$ bits : 
${\Nint = \lfloor \frac{\Norb-1}{64} \rfloor + 1}$

%\item [$\Ndav$] : Number of vectors in the Davidson diagonalization
%
%\item [$\Nperm$] : Number of permutations

\item [$\NFCI$] : Number of determinants in the FCI space

\item [$|\mathcal{D}|$] : Cardinality of the set $\mathcal{D}$.

\item [$\kalpha$] : external determinant
\end{itemize}


%centering in tables



\chapter{Introduction}

%During the 3 years I spent at the LCPQ, I worked on improving the \QP, a suit of quantum chemistry code intended for developers, which focuses on ease of implementation and parallelism.

Quantum chemistry is a discipline which relies on very expensive computations.
The scalings of wave function methods lie between $\order{N^5}$ and
$\order{N^8}$, where $N$ is proportional to the number of electrons in the
system. Therefore, treating performing accurate calculations requires both
approximations that can reduce the scaling, and an efficient implementation
that can take advantage of modern architectures. The work presented in this
thesis is more centered on this last aspect. 

In 1965, Gordon Moore predicted that the number of transistors in an integrated
circuit would double about every two years (the so-called Moore's
law).\cite{Moore}  Rapidly, this ``law'' was interpreted as an expected
$2\times$ gain in performance every 18 months, which became an industrial goal.

The development of today's most popular codes of the community
(Molpro\cite{Molpro}, Molcas\cite{Molcas}, or Gaussian\cite{g09}\dots) was
initiated in the 1990's.  At that time, the increase of computational power
from one generation of supercomputers to the next one was mostly due to the
increase of the frequency of the processors. the amount of random access memory
was small, the time to access data from disk was slow, and the energy
consumption of the most powerful computer was 236kW, which was not an
economical concern.\cite{top500_93}

At the beginning of the years 2000, having increased continuously both the number
of processors and their frequency raised the power consumption of
supercomputers by two orders of magnitude, raising accordingly the annual
electricity bill.  The only way to slow down this need for electricity while
keeping alive Moore's law was to keep the frequency fixed (between $1$ and
$4$~GHz), and increase the number of CPU cores.  The consequence of such a
choice was that ``free lunch'' was over, and the programmers now had to parallelize
their programs to make them run faster.\cite{Sutter_2005}
At the same time, computer scientists
realized that the increase of performance in memory access was slower than the
increase in computational power,\cite{Wulf1995Mar} and that the floating-point
operation (or flop) count would soon not be the bottleneck, and that data
movement would be the concern. This change was called the \emph{memory wall}.

So today, the situation is completely different from the 1990's.
Moore's law has ended,\cite{Khan2018Jan} the CPU frequency tends to decrease,
hundreds of thousands of cores need to be handled, data movement is the
principal concern, and disk access times are prohibitively high.
The work presented in this thesis is in the context of this change of paradigm
that has been going on for the last decade.
The traditional sequential algorithms of quantum chemistry are currently being
redesigned so as to be replaced by parallel equivalents by multiple groups
around the world, and this has also an influence on methodological development.

Initially, this work may been have expected to focus on methods that are by
design adapted to massively parallel architectures, such as Monte-Carlo methods
(stochastic methods), which are composed of a large number of independent tasks
(\emph{embarrassingly parallel} algorithms). In addition, they often are able
to yield a satisfactory result for just a fraction of the cost of the
equivalent deterministic, exact computation. An example of the move toward this
type of method is the recently developed \emph{Full Configuration Interaction
Quantum Monte Carlo} (FCIQMC).\cite{Booth_2009} FCIQMC can be interpreted as a
Monte-Carlo variant of older selection algorithms such as
CIPSI,\cite{Huron_1973} that are iterative and thus a priori not well adapted to
massively parallel architectures.
Unlike Monte-Carlo, most wavefunction methods are not easy to parallelize.

The \QP developed at the LCPQ is a suite of wavefunction quantum
chemistry methods, that strives to allow easy implementation and
experimentation of new methods, and to make parallel computation
as simple and efficient as possible.
Hence, the initial choice of the \QP was to go in  the direction of
determinant-driven algorithms, as opposed to the more traditional
integral-driven algorithms.
A determinant-driven approach essentially implies that the wavefunction
is expressed as a linear combination of determinants, and that the 
outermost loops of the algorithms loop over determinants.
On the other hand, integral-driven algorithms have their outermost loop
on the two-electron integrals which appear in the expression of the matrix
elements in the determinant basis.
In the context of \emph{configuration interaction} (CI) or perturbative
methods, the determinant-driven approach simplifies the development and allows
the researchers to test new ideas very quickly.  These algorithms allow more
flexibility than their integral-driven
counterparts,\cite{povill_efficient_1995} but they have been known for years to
be by far less efficient for solving the same problem.  High-precision
calculations are always in a regime where the number of 
determinants is larger than the number of determinants, which justifies the
integral-driven choice.  Today, programming imposes parallelism, and if
determinant-driven calculations are better adapted to parallelism, such methods
could regain in popularity.  The work presented in this thesis focuses on
exploring determinant-driven approaches via the improvement of the \QP from the
methodological, algorithmic and the implementational points of views.


Somewhat logically, the first focus was acceleration and parallelization of the
Davidson diagonalization, which is a pivotal point for CI methods. A naive
determinant-driven algorithm implies a quadratic scaling with the number of
determinants, while the integral-driven algorithm is expected to scale
linearly. This fact gave us some insight that there was room for improvement
in this step. 

The second focus was the improvement of the determinant selection algorithm
which is the main method used by the \QP to build compact wavefunctions
suitable for determinant-driven computations. In a nutshell, the principle is
to incrementally build a variational wavefunction by scavenging its external
space for determinants that interact with it. While the significant
improvement that was brought to this implementation was in itself the most
important part of this work, it also turned out to be the basis for the subsequent
implementation of other algorithms. Indeed, efficiently implementing this
method raised the fundamental question of connecting a variational wavefunction
to its external space ; that is, gathering data to go beyond what is readily
available in it. The next steps were partly guided by the aversion to waste
data gathered during the selection.

Our selection algorithm, CIPSI, implies computing a perturbative contribution
for external determinants, and include the ones of largest contribution into
the internal space in which the variational wavefunction is expressed.
$\EPT$, the sum of all the contributions of the external determinants,
approximates how much energy the variational wavefunction is missing compared
to  the exact solution in the same basis set, namely the \emph{Full Configuration Interaction} or Full CI. However to
perform an acceptably accurate selection, not all external determinants need to
be considered, nor does each contribution need be known with great accuracy.\cite{Bytautas_2009}
This allows for approximations too severe for the sum of all computed
contributions to yield an accurate estimation $\EPT$. Incidentally, the computation
of $\EPT$ is much more time consuming than determinant selection. To
make this step more affordable, we designed a hybrid deterministic-stochastic
scheme which enabled us to get an accurate value for $\EPT$ by
computing just a few percent of all the contributions.

The computation of $\EPT$ allows to correct the energy of the 
wavefunction by taking into account its external space. Unfortunately, it only
improves the energy, but leaves the wavefunction unchanged. Based on the
shifted-\Bk algorithm, using our CIPSI implementation and the hybrid
deterministic-stochastic scheme we were able to refine the wavefunction under
the effect of a stochastically estimated external space using
a Hamiltonian dressed by a matrix computed semi-stochastically.

In addition, we set up a general framework to enable refining of the
variational wavefunction under the effect of any
external space, with a stochastic estimation.
This was experimented by implementing a stochastic selected \emph{multi-reference
coupled cluster with singe and double substitutions} (MR-CCSD).

The efficiency of the implemented algorithms is exposed, and the code
was used in numerous applications, in particular to obtain reference
excitation energies for difficult molecular systems. The high quality
of the CIPSI wavefunction was also used for quantum Monte Carlo calculations
to characterize the ground state of the Fe-S molecule.

Of course, the technical considerations were not the focus of the different
articles that were produced. In particular, no publication was made about all
the detail of our CIPSI implementation. Because my work focused on the actual
implementation of the methods at least as much as on the theory behind them,
this thesis is an opportunity to discuss in depth the implementation.
I expect this document to be one of the major pieces of documentation for
developers willing to understand deeply the implementation of the \QP, 
so I decided to write this thesis in English.



\chapter{Wave function methods}
\minitoc
\subfile{methods}

\chapter{Determinant-driven computation of the matrix elements}
\minitoc
\subfile{det_driven}

\chapter{Diagonalization with Davidson's algorithm}
\minitoc
\subfile{davidson}

\chapter{Selection with the CIPSI criterion}
\minitoc
\subfile{cipsi}

\chapter{Computation of the second-order perturbative correction}
\minitoc
\subfile{pt2}

\chapter{Stochastic Matrix dressing}
\minitoc
\subfile{matrix_dressing}

\chapter{Application of Stochastic Matrix dressing to MRCC}
\minitoc
\subfile{exp_dressing}

\chapter{Performance measurements}
\minitoc
\subfile{perf}

\chapter{Applications}
\minitoc
\subfile{applications}

\chapter{Conclusion}

Significant improvements were brought to the \QP. Some were single-core optimization, and others were for adapting the algorithms for a better load balancing in the
parallel regime.

The Davidson diagonalization, which is at the center of variational methods, suffers from the impossibility to fully store the Hamiltonian. A solution is to resort to \emph{direct methods}, recomputing its matrix elements on the fly at each iteration. While an extremely fast method was already available to detect zero matrix elements,\cite{Scemama_2013} the former implementation still had to iterate over the $\sim \Ndet^2$ matrix elements. Now, determinants are split in disjoint sets, which are often identifiable as entirely disconnected from one another. Thus only a small fraction of the matrix elements need to be explored, and a linear-scaling algorithm was proposed.
While the parallelization of this method was somewhat challenging, due to the elementary tasks being extremely unbalanced, a distributed implementation was realized with rather satisfying parallel speedups, typically $35\times$ for $50$ nodes ($1~800$ cores) with respect to the $36$-core single-node reference.

The CIPSI selection algorithm, for which the previous implementation examined the external determinants one by one, was enormously improved, allowing for some applications that were not feasible so far.\cite{Scemama_2018,1806.05115} Several different optimizations were used, reducing the cost of finding connections between external and internal determinants (``batch'' approach, filtering), as well as the cost of computing the corresponding matrix element in the Hamiltonian (phase mask, systematic determination of excitations). Again, a distributed implementation could be realized after 
solving the problems related to load imbalance.
Because the computation of $\EPT$ was done by the same algorithm but did not allow for as much approximation ---~and thus was much more expensive~--- a hybrid stochastic-deterministic approach was imagined. $\EPT$ being in itself an approximation for the Full-CI energy, an exact value is indeed not required. Our scheme allows to compute $\EPT$ with an error bar smaller than the typical error of $E_{\text{var}} + \EPT$ versus the Full-CI energy, for a few percent of the cost of the full deterministic computation.

To get the best of the data we were already able to compute, we implemented the shifted-\Bk method, which uses the energy contributions computed by $\EPT$ to refine the wavefunction. It essentially creates an external space of determinants $\kalpha$ whose coefficients are perturbatively estimated, and allows them to act on the coefficients of the wavefunction in the internal space. This method requires the computation of a dressing matrix, which we could estimate stochastically in a way similar to what we proposed for $\EPT$ (stochastic matrix dressing).
The challenge in this case was to estimate, instead of a scalar, a vector of size $\Ndet$, which can be up to a few million elements. The storage and network issues could be solved by setting up a system of predefined checkpoints, a modest drawback being the impossibility to get an estimated dressing matrix outside of those checkpoints.

Finally, this stochastic matrix dressing computation was extended to another external space, that of the Multi-Reference Coupled-Cluster we had previously implemented deterministically,\cite{Garniron_2017} which allowed to explore some possibilities of the bitstring-based determinant-driven approach.

During the multiple steps of evolution of the program, more and more applications were made possible.\cite{Loos_2018,Garniron_2018,Giner_2017,Garniron_2017,Garniron_2017b,Scemama_2018,1806.05115} This gave to the \QP more visibility, and it was selected as a benchmark code for the choice of the new supercomputer of the CALMIP center. Moreover, different groups started to use it for applications and use it to develop new ideas. For example, the Argonne group is currently implementing complex orbitals to 
adapt the \QP to solids.

\appendix

\chapter{A Jeziorski-Monkhorst fully uncontracted multi-reference perturbative treatment. I. Principles, second-order versions, and tests on ground state potential energy curves \cite{Giner_2017}}
\includepdf[page=2-]{article_jmmrpt2}

\bibliographystyle{ieeetr}
\bibliography{thesis}

%\appendix 
%\chapter{Quantum Package basics}
%\minitoc
%\subfile{qp_general}

\end{document}




