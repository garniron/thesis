 
\documentclass[./thesis.tex]{subfiles}
\begin{document}


Quantum chemistry aims at describing the electronic structures of molecular systems.
For atoms of the first 3 rows of the periodic table, relativistic effects can be neglected and the velocity of the nuclei is considered negligible compared to that of the electrons (Born-Oppenheimer approximation). In this context, the model system is a cloud of $N$ electrons and a set of $M$ nuclei considered punctual, immobile charges. It can be described by solving Shrödinger's equation for electrons~:
\begin{equation}
 \widehat{H} \Psi({\bf x}_1,\dots,{\bf x}_N) = E \Psi_n({\bf x}_1,\dots,{\bf x}_N)
\end{equation}
where $\Psi$ is the electronic wave function and $E$ is the associated energy. $\widehat H$ is the non-relativistic electronic Hamiltonian operator
\begin{equation}
\widehat{H} = \sum_{i=1}^{N} \Big ( -\frac{1}{2} \Delta_i - \sum_{j=1}^M \frac{Z_j}{|{\bf r}_i - {\bf R}_j|} \Big ) + \sum_{i=1}^{N} \sum_{k>i}^{N} \frac{1}{|{\bf r}_i - {\bf r}_k|}
\end{equation}
${\bf r}_i$ the spatial coordinates of electron $i$, ${\bf R}_j$ and $Z_j$ respectively the spatial coordinate and charge of nuclei $j$.

\section{Slater determinants}

Because of the fermionic nature of electrons, $\Psi$ must satisfy the condition of being anti-symmetric with respect to electron permutation of same-spin electrons.
\begin{equation}
\Psi({\bf r}_1, {\bf r}_2,\dots,{\bf r}_N) = -\Psi({\bf r}_2, {\bf r}_1,\dots,{\bf r}_N)
\end{equation}
Throughout this thesis, we will use the so-called \emph{spin-free} formalism, in which the above condition is achieved by defining two types of electrons, $\alpha$ and $\beta$, and writing the wavefunction as a \emph{Waller-Hartree double determinant},\cite{Pauncz_1989} namely the product of two determinants associated with $\alpha$ and $\beta$ electrons respectively.
\begin{equation}
\begin{array}{c}
 \Psi({\bf r}_1,\dots,{\bf r}_{\Na},{\bf r}_{\Na+1},\dots,{\bf r}_N;
      \alpha_1,\dots,\alpha_{\Na},\beta_{\Na+1},\dots,\beta_N) = \\
D_\alpha({\bf r}_1,\dots,{\bf r}_{\Na}) \times D_\beta({\bf r}_{\Na+1},\dots,{\bf r}_N) = \\
\left|
 \begin{array}{ccc}
 \varphi_1({\bf r}_1) & \dots & \varphi_1({\bf r}_{\Na}) \\
 \vdots               & \ddots &   \vdots             \\
 \varphi_{\Na}({\bf r}_1) & \dots & \varphi_{\Na}({\bf r}_{\Na}) \\
 \end{array}
\right|
\left|
 \begin{array}{ccc}
 \varphi_1({\bf r}_{\Na+1}) & \dots & \varphi_1({\bf r}_{N}) \\
 \vdots               & \ddots &   \vdots             \\
 \varphi_{N_\beta}({\bf r}_{\Na+1}) & \dots & \varphi_{N_\beta}({\bf r}_{N}) \\
 \end{array}
\right| \\ 
\end{array} \\
\label{eq:slater}
\end{equation}
with $\{ \varphi_i \}$ a set of one-electron functions referred to as \emph{molecular orbitals}, or \emph{MO}, typically chosen orthogonal. This type of wavefunction is the spin-free formulation of a \emph{Slater determinant}. We call $N_\alpha$ and $N_\beta \leq N_\alpha$ the number of $\alpha$ and $\beta$ electrons.

Molecular orbitals are typically defined as linear combinations of \emph{atomic orbitals}, or \emph{AO}, here noted $\chi_k$
\begin{equation}
 \varphi_i({\bf r}) = \sum_k C_{ki} \chi_k({\bf r}).
\end{equation}
These functions qualify the used \emph{basis set}, and are usually themselves pre-defined linear combinations of Gaussian functions. This is a restriction put on the form of the wavefunction, therefore it is known as the \emph{finite basis-set approximation}.
In the Hartree-Fock method, the wave function is a single Slater determinant, where the $C_{ki}$ coefficients associated with molecular orbitals are optimized so as to minimize the energy. This method, however is missing some important physical effects. For instance, using Eq.\eqref{eq:slater} one can see that in this model opposite-spin electrons are statistically independent (or \emph{uncorrelated}):
\begin{equation}
\begin{split}
\left[ \Psi_\textrm{HF}({\bf r}_1,\dots,{\bf r}_{\Na},{\bf r}_{\Na+1},\dots,{\bf r}_N;
      \alpha_1,\dots,\alpha_{\Na},\beta_{\Na+1},\dots,\beta_N) \right]^2 = \\
\left[ D_\alpha({\bf r}_1,\dots,{\bf r}_{\Na}) \times D_\beta({\bf r}_{\Na+1},\dots,{\bf r}_N) \right]^2 = \\
\left[ D_\alpha({\bf r}_1,\dots,{\bf r}_{\Na}) \right]^2 \times \left[ D_\beta({\bf r}_{\Na+1},\dots,{\bf r}_N) \right]^2.
\end{split}
\end{equation}

\section{Electron correlation}
Even though typically, only one or a few $\ket{\Psi_n}$ associated with lowest eigenvalues are of interest, the Shrödinger's equation cannot be solved exactly (except for a few small systems), and more or less drastic approximations need to be used. 

Electron correlation is defined as\cite{Lowdin_1959}
\begin{equation}
\Ecor = E_\text{exact} - E_\text{HF}
\end{equation}
where $E_\text{HF}$ is the \emph{Hartree-Fock limit}, i.e. the limit to which the Hartree-Fock energy converges when the size of the basis-set increases.

To include electron correlation effects, $\Psi$ must be expressed in a basis of $N$-electron functions. 
Such a basis is $\{\ket D_i \}$ the set of all the possible Slater determinants that can be built by putting $N_\alpha$ electrons in $M$ orbitals and $N_\beta$ electrons in $M$ orbitals.
The eigenvectors of $\widehat{H}$ are consequently expressed as a linear combination of Slater determinants 
\begin{equation}
\ket{\Psi_n} = \sum_{i} c_i^n \ket{D_i}.
\end{equation}
Solving the eigenequation for state $n$ in this basis is referred to as \emph{full configurations interaction (FCI)} and yields a solution for Schrödinger's equation that is exact for the given basis set.
This is however only achievable for very small systems, given that $\NFCI$ the size of the determinants basis scales factorially with the number of molecular orbitals
\begin{equation}
\NFCI = \frac{M!}{N_\alpha ! (M-N_\alpha)!} \times \frac{M!}{N_\beta ! (M-N_\beta)!}
\end{equation}
Post-Hartree-Fock methods are trying to circumvent this problem, and therefore are essentially approximations of FCI.
%Different approaches exist.

\alert{ Il faut mettre ici l'expression des elements de matrice de H dans la
base des determinants.  Il faut aussi dire que pour Hartree-Fock, en utilisant
les equations de Roothaan on peut resoudre le probleme dans la base des AOs.
Par contre, le probleme est beaucoup complique dans une base de fonctions a
N-electrons car chaque element de matrice doit faire intervenir des integrales
a N electrons.  Si les fonctions de base a N-electrons sont des determinants
fabriques a partir de fonctions a 1 electron orthonormales, telles que les
determinants de Slater, le calcul des elements de matrice de H devient beaucoup
plus simple grace aux regles de Slater-Condon qui permettent de ne faire
intervenir que des integrales a 2 electrons. Il faut donc introduire les regles
de Slater-Condon.  Il faut aussi introduire ici la four-index transformation,
qui est un des bottlenecks des methodes post-HF a cause de son scaling en
$\order{N^5}$.  } 

\section{Variational post-Hartree-Fock methods}

In variational methods, Schrödinger's equation is solved in an $N$-electron basis.
Generally speaking, solving Schrödinger's equation in a basis of Slater determinants is called \emph{configuration interaction (CI)}, the FCI being the particular case where the whole $\{\ket {D_i} \}$ set is used. The general idea of these methods is to select \textit{a priori} a relevant subset of Slater determinants in which the CI problem will be solved.

One usual approach is to effectively reduce the number of molecular orbitals, by performing a FCI in a reduced set of orbitals and freezing the occupation status for the others. This is referred to as \emph{Complete Active Space Configuration Interaction (CAS-CI)}. Choosing the CAS orbitals can require some expertise. The CAS-SCF method minimizes the energy by both performing a CAS-CI and optimizing the molecular orbitals.

Another usual approach is to select determinants according to their excitation degree --- by how many occupied orbitals they differ --- with respect to some reference. If this reference is the Hartree-Fock determinant and only single and double excitations are considered, the method is known as \emph{Configuration Interaction with Single and Double excitations (CISD)}. Alternatively, the reference can be a CAS, in which case it is known as \emph{Multi-Reference Configuration Interaction (MR-CI)}.


\alert{On voit que pour faire un CI, on a besoin de toutes les integrales
bielectroniques. Donc ca coute au moins $\order{N^5}$.  Il faut diagonaliser
$H$ dans la base des determinants, et il y en a souvent un tres grand nombre
(plusieurs millions, voire milliards). Donc je pense qu'il faut introduire
Davidson ici. Mettre dans la partie 'determiant driven' l'implementations qu'on
a dans le QP, et tes reflexions sur Davidson en dans les perspectives a la fin.
}

\section{Perturbative methods}

\alert{Pioche un peu chez Manus pour introduire MP2 et Epstein Nesbet.}

\alert{On voit que pour MP2, on n'a pas besoin de toutes les integrales
bielectroniques : les $\braket{vv}{vv}$ ne sont pas necessaires. Donc ca coute
forcement moins cher que le CI.}

\section{Selected CI methods}

These methods rely on the same principle as the usual CI approaches, except that determinants aren't chosen \textit{a priori} based on an occupation or excitation criterion, but selected among the entire set of determinant based on their estimated contribution to the FCI wavefunction. Usual methods can be seen as an exact resolution of Schrödinger's equation for a complete, well-defined set of determinant (and for a given basis set), while selected CI methods are more of a truncation of the FCI.
The main advantages of these methods compared to the \alert{variational} ones, are that since the most relevant determinants are considered, they will typically yield a more accurate description of physical phenomenon, and a much lower energy for an equivalent number of determinants.
It has been noticed long ago that, even inside a predefined subspace of determinants, only a small number significantly contributes to the wavefunction. Therefore, a posteriori selection of determinants is a rather natural idea that has been implemented from the late 60s \alert{voler les refs de manus}. The approach we are using is based on the \emph{Configuration Interaction using a Perturbative Selection (CIPSI)} developped by \alert{voler les refs de manus}, that iteratively selects determinants by using a perturbative criterion. 

There is however a computational downside. In variational methods, the rule by which determinants are selected is known a priori, and therefore, one can map a particular determiant to some row or column index\cite{Knowles_1984}. As a consequence, it can be systematically determined to which matrix element of $\widehat{H}$ a bielectronic integral contributes. This allows for the implementation of so-called \emph{intergral-driven} methods, that work essentially by iterating over integrals.
On the contraty, in selected method, determinants aren't known a priori. Therefore an explicit list has to be maintained, and there is no instantaneous way to know whether a determinant has been selected, or what its index is. Consequently, so-called \emph{determinant-driven} approaches will be used, in which iteration is done over determinants rather than integrals. This can be a lot more costly, since the number of determinants is typically much greater than the number of integrals. The former scales as $N!$ while the later scales as $N^4$ with the number of MO.
Furthermore, determinant-driven methods require an effective way to compare determinants in order to extract an excitation operators, and a way to rapidly fetch the associated integral(s).

Because of this high computational cost, approximations have been proposed, for example we use the one by \alert{cipsi stefano}, and recently, \alert{heat bath} have taken farther the idea of a more approximate but a lot cheaper selection.

An alternate approach to selection is \alert{a clarifier}, where walkers move from determinants to determinant with probabilities dependent on the matrix elements

\begin{equation}
\ket{\Psi^{n}} = \sum_{i \in \mathcal{D}^n} c_i^{n} \ket{D^n_i}
\end{equation}
\begin{equation}
e_\alpha = \frac{\Hij{\Psi^n}{\alpha}^2}{E^n - H_{\alpha \alpha}}
\end{equation}
\begin{equation}
\mathcal{D}^{n+1} = \mathcal{D}^{n} \cup \{ \alpha^\star \}^n
\end{equation}
\begin{equation}
E_{PT2}^n = \sum_{\alpha \in \{\alpha \}^n} e_\alpha
\end{equation}

\alert{Ici, tu peux expliquer que dans les methodes selectionnees a priori, on
fabrique tous les determinants a partir d'une regle predefinie. Donc on peut
facilement faire une fonction d'adressage des determinants. Pour le CAS, c'est
la meme que pour le FCI (citer \cite{Knowles_1984}). Et pour le CISD, on peut
utiliser les operateurs d'excitations. Il est donc facile quand on a une
integrale sous la main de savoir a quels elements de matrice elle contribue, et
on peut donc utiliser des approches de type \emph{integral-driven}. Quand on a
un jeu arbitraire de determinants, on ne peut plus le faire facilement et on
doit alors recourir aux approches \emph{determinant-driven}. La transition est
facile avec le chapire suivant.}

\end{document}
